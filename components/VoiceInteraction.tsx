/**
 * @file VoiceInteraction.tsx
 * @description YYCÂ³ AIå°è¯­æ™ºèƒ½æˆé•¿å®ˆæŠ¤ç³»ç»Ÿè¯­éŸ³äº¤äº’ç»„ä»¶ï¼Œæä¾›è¯­éŸ³è¯†åˆ«å’Œäº¤äº’åŠŸèƒ½
 * @author YYCÂ³å›¢é˜Ÿ <admin@0379.email>
 * @version 1.0.0
 */

"use client"

import { useState, useRef, useCallback } from "react"
import { motion } from "framer-motion"
import { reportError } from "@/lib/global-error-handler"

interface VoiceInteractionProps {
  onTranscript: (text: string) => void
  onEmotionDetected: (emotion: string) => void
  className?: string
}

interface WindowWithSpeechRecognition extends Window {
  SpeechRecognition?: typeof SpeechRecognition
  webkitSpeechRecognition?: typeof SpeechRecognition
}

interface WindowWithAudioContext extends Window {
  webkitAudioContext?: typeof AudioContext
}

interface SpeechRecognitionResult {
  isFinal: boolean
  transcript: string
}

interface SpeechRecognitionEvent {
  resultIndex: number
  results: SpeechRecognitionResultList
}

interface SpeechRecognitionErrorEvent {
  error: string
}

export default function VoiceInteraction({
  onTranscript,
  onEmotionDetected,
  className = ""
}: VoiceInteractionProps) {
  const [isRecording, setIsRecording] = useState(false)
  const [isProcessing, setIsProcessing] = useState(false)
  const [transcript, setTranscript] = useState("")
  const [audioLevel, setAudioLevel] = useState(0)
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const audioContextRef = useRef<AudioContext | null>(null)
  const analyserRef = useRef<AnalyserNode | null>(null)
  const animationFrameRef = useRef<number | null>(null)

  // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
  const isSupported = () => {
    return !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia && window.SpeechRecognition || (window as WindowWithSpeechRecognition).webkitSpeechRecognition)
  }

  // è¯­éŸ³è¯†åˆ«
  const startSpeechRecognition = useCallback(() => {
    if (!isSupported()) {
      console.warn("æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«åŠŸèƒ½")
      return
    }

    const SpeechRecognition = (window as WindowWithSpeechRecognition).SpeechRecognition || (window as WindowWithSpeechRecognition).webkitSpeechRecognition
    if (!SpeechRecognition) return

    const recognition = new SpeechRecognition()
    recognition.continuous = true
    recognition.interimResults = true
    recognition.lang = "zh-CN"

    recognition.onresult = (event: SpeechRecognitionEvent) => {
      let finalTranscript = ""
      let interimTranscript = ""

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript
        if (event.results[i].isFinal) {
          finalTranscript += transcript + " "
        } else {
          interimTranscript += transcript
        }
      }

      const fullTranscript = finalTranscript + interimTranscript
      setTranscript(fullTranscript)

      if (finalTranscript.trim()) {
        onTranscript(finalTranscript.trim())
        detectEmotion(finalTranscript.trim())
      }
    }

    recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
      reportError(new Error(event.error), { component: 'VoiceInteraction', action: 'speechRecognition', errorType: event.error })
      if (event.error === "no-speech") {
        setIsRecording(false)
      }
    }

    recognition.onend = () => {
      setIsRecording(false)
    }

    recognition.start()
    return recognition
  }, [onTranscript])

  // æƒ…æ„Ÿæ£€æµ‹ï¼ˆç®€åŒ–ç‰ˆï¼‰
  const detectEmotion = (text: string) => {
    const emotionKeywords = {
      happy: ["å¼€å¿ƒ", "é«˜å…´", "å¿«ä¹", "ç¬‘", "å“ˆå“ˆ", "æ£’", "å¥½", "å–œæ¬¢", "çˆ±"],
      sad: ["éš¾è¿‡", "ä¼¤å¿ƒ", "å“­", "ä¸èˆ’æœ", "ç—›", "æ€•"],
      excited: ["å…´å¥‹", "æ¿€åŠ¨", "å¤ªæ£’äº†", "å“‡", "æƒŠå–œ"],
      calm: ["å¹³é™", "å®‰é™", "èˆ’æœ", "æ”¾æ¾"]
    }

    let detectedEmotion = "neutral"
    let maxScore = 0

    Object.entries(emotionKeywords).forEach(([emotion, keywords]) => {
      const score = keywords.reduce((count, keyword) => {
        return count + (text.includes(keyword) ? 1 : 0)
      }, 0)

      if (score > maxScore) {
        maxScore = score
        detectedEmotion = emotion
      }
    })

    if (maxScore > 0) {
      onEmotionDetected(detectedEmotion)
    }
  }

  // éŸ³é¢‘å¯è§†åŒ–
  const startAudioVisualization = useCallback((stream: MediaStream) => {
    audioContextRef.current = new (window.AudioContext || (window as WindowWithAudioContext).webkitAudioContext)()
    analyserRef.current = audioContextRef.current.createAnalyser()
    const source = audioContextRef.current.createMediaStreamSource(stream)
    source.connect(analyserRef.current)
    analyserRef.current.fftSize = 256

    const updateAudioLevel = () => {
      if (!analyserRef.current) return

      const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount)
      analyserRef.current.getByteFrequencyData(dataArray)

      const average = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length
      setAudioLevel(average / 255)

      animationFrameRef.current = requestAnimationFrame(updateAudioLevel)
    }

    updateAudioLevel()
  }, [])

  // å¼€å§‹å½•éŸ³
  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      })

      // å¼€å§‹è¯­éŸ³è¯†åˆ«
      startSpeechRecognition()

      // éŸ³é¢‘å¯è§†åŒ–
      startAudioVisualization(stream)

      // è®¾ç½®å½•éŸ³å™¨ï¼ˆå¤‡ç”¨ï¼‰
      const mediaRecorder = new MediaRecorder(stream)
      mediaRecorderRef.current = mediaRecorder
      mediaRecorder.start()

      setIsRecording(true)
      setIsProcessing(false)
    } catch (error) {
      reportError(error as Error, { component: 'VoiceInteraction', action: 'microphoneAccess' })
      alert("è¯·å…è®¸è®¿é—®éº¦å…‹é£ä»¥ä½¿ç”¨è¯­éŸ³åŠŸèƒ½")
    }
  }

  // åœæ­¢å½•éŸ³
  const stopRecording = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== "inactive") {
      mediaRecorderRef.current.stop()
    }

    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current)
    }

    if (audioContextRef.current) {
      audioContextRef.current.close()
    }

    setIsRecording(false)
    setIsProcessing(true)

    // æ¨¡æ‹Ÿå¤„ç†å»¶è¿Ÿ
    setTimeout(() => {
      setIsProcessing(false)
      setAudioLevel(0)
    }, 1000)
  }

  // æ¸…ç†èµ„æº
  const cleanup = () => {
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current)
    }
    if (audioContextRef.current) {
      audioContextRef.current.close()
    }
  }

  // ç»„ä»¶å¸è½½æ—¶æ¸…ç†
  const handleUnmount = useCallback(() => {
    cleanup()
  }, [])

  if (!isSupported()) {
    return (
      <div className={`text-center p-4 bg-gray-50 rounded-lg ${className}`}>
        <p className="text-gray-600 text-sm">
          æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³äº¤äº’åŠŸèƒ½
        </p>
      </div>
    )
  }

  return (
    <div className={`voice-interaction ${className}`}>
      {/* äº¤äº’æŒ‰é’® */}
      <div className="flex flex-col items-center space-y-4">
        <motion.button
          whileHover={{ scale: 1.05 }}
          whileTap={{ scale: 0.95 }}
          onClick={isRecording ? stopRecording : startRecording}
          disabled={isProcessing}
          className={`relative w-20 h-20 rounded-full flex items-center justify-center transition-all ${
            isRecording
              ? "bg-red-500 hover:bg-red-600 shadow-red-200"
              : isProcessing
              ? "bg-gray-400 cursor-not-allowed"
              : "bg-blue-600 hover:bg-blue-700 shadow-blue-200"
          } shadow-lg`}
        >
          {isProcessing ? (
            <div className="animate-spin rounded-full h-8 w-8 border-b-2 border-white"></div>
          ) : isRecording ? (
            <div className="relative">
              <div className="w-8 h-8 bg-white rounded-full"></div>
              <div className="absolute inset-0 flex items-center justify-center">
                <div className="w-4 h-4 bg-red-500 rounded-full animate-pulse"></div>
              </div>
            </div>
          ) : (
            <svg className="w-8 h-8 text-white" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z"/>
              <path d="M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z"/>
            </svg>
          )}
        </motion.button>

        <div className="text-center">
          <p className="text-sm font-medium text-gray-700">
            {isProcessing
              ? "æ­£åœ¨å¤„ç†..."
              : isRecording
              ? "æ­£åœ¨å½•éŸ³..."
              : "ç‚¹å‡»å¼€å§‹è¯­éŸ³è¾“å…¥"
            }
          </p>
          <p className="text-xs text-gray-500 mt-1">
            {isRecording && "è¯´å‡ºæ‚¨æƒ³å¯¹å°è¯­è¯´çš„è¯"}
          </p>
        </div>
      </div>

      {/* éŸ³é¢‘å¯è§†åŒ– */}
      {isRecording && (
        <div className="mt-4 flex justify-center space-x-1">
          {Array.from({ length: 5 }).map((_, i) => (
            <motion.div
              key={i}
              className="w-1 bg-blue-500 rounded-full"
              style={{ height: `${20 + audioLevel * 40 * Math.random()}px` }}
              animate={{
                scaleY: [1, 1 + audioLevel, 1]
              }}
              transition={{
                duration: 0.2,
                repeat: Infinity,
                delay: i * 0.1
              }}
            />
          ))}
        </div>
      )}

      {/* å®æ—¶è½¬å½•æ˜¾ç¤º */}
      {transcript && (
        <motion.div
          initial={{ opacity: 0, y: 10 }}
          animate={{ opacity: 1, y: 0 }}
          className="mt-4 p-3 bg-sky-50 rounded-lg"
        >
          <p className="text-sm text-gray-700">
            <span className="font-medium">è¯†åˆ«ç»“æœï¼š</span> {transcript}
          </p>
        </motion.div>
      )}

      {/* åŠŸèƒ½æç¤º */}
      <div className="mt-4 text-center">
        <p className="text-xs text-gray-500">
          ğŸ”Š è¯­éŸ³è¯†åˆ«æ”¯æŒä¸­æ–‡ï¼Œå¯ä»¥ä¸å°è¯­è¿›è¡Œè‡ªç„¶å¯¹è¯
        </p>
      </div>
    </div>
  )
}