#!/bin/bash

# YYCÂ³ AIå°è¯­æ™ºèƒ½æˆé•¿å®ˆæŠ¤ç³»ç»Ÿ - Dockeréƒ¨ç½²è„šæœ¬
# Intelligent Pluggable Mobile AI System - Docker Deployment Script
# Phase 1 Week 7-8: DevOpsä¸éƒ¨ç½²ä¼˜åŒ–

set -e

# é¢œè‰²è¾“å‡º
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ£€æŸ¥Dockerå’ŒDocker Compose
check_dependencies() {
    log_info "æ£€æŸ¥ä¾èµ–é¡¹..."

    if ! command -v docker &> /dev/null; then
        log_error "Docker æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£… Docker"
        exit 1
    fi

    if ! command -v docker-compose &> /dev/null; then
        log_error "Docker Compose æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£… Docker Compose"
        exit 1
    fi

    log_success "ä¾èµ–é¡¹æ£€æŸ¥å®Œæˆ"
}

# åˆ›å»ºå¿…è¦çš„ç›®å½•
create_directories() {
    log_info "åˆ›å»ºå¿…è¦çš„ç›®å½•..."

    mkdir -p data logs uploads knowledge
    mkdir -p logs/nginx logs/app
    mkdir -p backups
    mkdir -p config/nginx/ssl
    mkdir -p monitoring/grafana/dashboards monitoring/grafana/datasources
    mkdir -p database/init
    mkdir -p redis

    log_success "ç›®å½•åˆ›å»ºå®Œæˆ"
}

# æ£€æŸ¥ç¯å¢ƒå˜é‡æ–‡ä»¶
check_env_file() {
    log_info "æ£€æŸ¥ç¯å¢ƒå˜é‡æ–‡ä»¶..."

    if [ ! -f .env.docker ]; then
        log_error ".env.docker æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºç¯å¢ƒå˜é‡æ–‡ä»¶"
        exit 1
    fi

    # æ£€æŸ¥å¿…éœ€çš„ç¯å¢ƒå˜é‡
    source .env.docker

    required_vars=("POSTGRES_PASSWORD" "REDIS_PASSWORD" "JWT_SECRET" "OPENAI_API_KEY")
    missing_vars=()

    for var in "${required_vars[@]}"; do
        if [ -z "${!var}" ] || [ "${!var}" = "your_${,,var}" ]; then
            missing_vars+=("$var")
        fi
    done

    if [ ${#missing_vars[@]} -gt 0 ]; then
        log_error "ä»¥ä¸‹ç¯å¢ƒå˜é‡éœ€è¦é…ç½®: ${missing_vars[*]}"
        exit 1
    fi

    log_success "ç¯å¢ƒå˜é‡æ£€æŸ¥å®Œæˆ"
}

# ç”ŸæˆSSLè¯ä¹¦ï¼ˆè‡ªç­¾åï¼Œç”Ÿäº§ç¯å¢ƒè¯·ä½¿ç”¨æ­£å¼è¯ä¹¦ï¼‰
generate_ssl_cert() {
    log_info "ç”ŸæˆSSLè¯ä¹¦..."

    if [ ! -f config/nginx/ssl/cert.pem ]; then
        openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
            -keyout config/nginx/ssl/key.pem \
            -out config/nginx/ssl/cert.pem \
            -subj "/C=CN/ST=Beijing/L=Beijing/O=YYC3/OU=AI/CN=localhost" \
            2>/dev/null || true

        if [ -f config/nginx/ssl/cert.pem ]; then
            log_success "SSLè¯ä¹¦ç”Ÿæˆå®Œæˆ"
        else
            log_warning "SSLè¯ä¹¦ç”Ÿæˆå¤±è´¥ï¼Œå°†ä½¿ç”¨HTTP"
        fi
    else
        log_success "SSLè¯ä¹¦å·²å­˜åœ¨"
    fi
}

# åˆ›å»ºæ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
create_database_init() {
    log_info "åˆ›å»ºæ•°æ®åº“åˆå§‹åŒ–è„šæœ¬..."

    cat > database/init.sql << 'EOF'
-- YYCÂ³ AIå°è¯­æ™ºèƒ½æˆé•¿å®ˆæŠ¤ç³»ç»Ÿ - æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
-- Intelligent Pluggable Mobile AI System - Database Initialization

-- åˆ›å»ºç”¨æˆ·è¡¨
CREATE TABLE IF NOT EXISTS users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    first_name VARCHAR(100) NOT NULL,
    last_name VARCHAR(100),
    role VARCHAR(50) DEFAULT 'parent',
    avatar_url TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- åˆ›å»ºå„¿ç«¥æ¡£æ¡ˆè¡¨
CREATE TABLE IF NOT EXISTS children (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    parent_id UUID REFERENCES users(id) ON DELETE CASCADE,
    name VARCHAR(100) NOT NULL,
    birth_date DATE NOT NULL,
    gender VARCHAR(10),
    avatar_url TEXT,
    interests JSONB DEFAULT '[]',
    learning_preferences JSONB DEFAULT '{}',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- åˆ›å»ºAIä¼šè¯è¡¨
CREATE TABLE IF NOT EXISTS ai_conversations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    child_id UUID REFERENCES children(id) ON DELETE CASCADE,
    ai_role VARCHAR(50) NOT NULL,
    title VARCHAR(200),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- åˆ›å»ºAIæ¶ˆæ¯è¡¨
CREATE TABLE IF NOT EXISTS ai_messages (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    conversation_id UUID REFERENCES ai_conversations(id) ON DELETE CASCADE,
    message_type VARCHAR(20) NOT NULL, -- 'user' or 'ai'
    content TEXT NOT NULL,
    ai_role VARCHAR(50),
    sentiment_analysis JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- åˆ›å»ºæˆé•¿è®°å½•è¡¨
CREATE TABLE IF NOT EXISTS growth_records (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    child_id UUID REFERENCES children(id) ON DELETE CASCADE,
    title VARCHAR(200) NOT NULL,
    description TEXT,
    category VARCHAR(50) NOT NULL,
    media_urls JSONB DEFAULT '[]',
    tags JSONB DEFAULT '[]',
    record_date DATE NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_users_email ON users(email);
CREATE INDEX IF NOT EXISTS idx_children_parent_id ON children(parent_id);
CREATE INDEX IF NOT EXISTS idx_ai_conversations_child_id ON ai_conversations(child_id);
CREATE INDEX IF NOT EXISTS idx_ai_messages_conversation_id ON ai_messages(conversation_id);
CREATE INDEX IF NOT EXISTS idx_growth_records_child_id ON growth_records(child_id);
CREATE INDEX IF NOT EXISTS idx_growth_record_record_date ON growth_records(record_date);

-- åˆ›å»ºæ›´æ–°æ—¶é—´è§¦å‘å™¨å‡½æ•°
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ language 'plpgsql';

-- ä¸ºéœ€è¦çš„è¡¨åˆ›å»ºæ›´æ–°æ—¶é—´è§¦å‘å™¨
CREATE TRIGGER update_users_updated_at BEFORE UPDATE ON users
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_children_updated_at BEFORE UPDATE ON children
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_ai_conversations_updated_at BEFORE UPDATE ON ai_conversations
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_growth_records_updated_at BEFORE UPDATE ON growth_records
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
EOF

    log_success "æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬åˆ›å»ºå®Œæˆ"
}

# æ„å»ºå’Œå¯åŠ¨æœåŠ¡
deploy_services() {
    local env=${1:-production}

    log_info "å¼€å§‹éƒ¨ç½²æœåŠ¡ (ç¯å¢ƒ: $env)..."

    # åŠ è½½ç¯å¢ƒå˜é‡
    source .env.docker

    if [ "$env" = "production" ]; then
        # ç”Ÿäº§ç¯å¢ƒ
        docker-compose -f docker-compose.yml up -d --build
    elif [ "$env" = "development" ]; then
        # å¼€å‘ç¯å¢ƒï¼ŒåŒ…å«è°ƒè¯•å·¥å…·
        docker-compose -f docker-compose.yml --profile development up -d --build
    else
        log_error "ä¸æ”¯æŒçš„ç¯å¢ƒ: $env"
        exit 1
    fi

    log_success "æœåŠ¡éƒ¨ç½²å®Œæˆ"
}

# ç­‰å¾…æœåŠ¡å¯åŠ¨
wait_for_services() {
    log_info "ç­‰å¾…æœåŠ¡å¯åŠ¨..."

    # ç­‰å¾…æ•°æ®åº“å¯åŠ¨
    log_info "ç­‰å¾…æ•°æ®åº“å¯åŠ¨..."
    timeout 60 bash -c 'until docker exec yyc3-postgres pg_isready -U yyc3; do sleep 2; done'

    # ç­‰å¾…Rediså¯åŠ¨
    log_info "ç­‰å¾…Rediså¯åŠ¨..."
    timeout 30 bash -c 'until docker exec yyc3-redis redis-cli ping; do sleep 2; done'

    # ç­‰å¾…ä¸»åº”ç”¨å¯åŠ¨
    log_info "ç­‰å¾…ä¸»åº”ç”¨å¯åŠ¨..."
    timeout 120 bash -c 'until curl -f http://localhost:8080/api/health; do sleep 5; done'

    log_success "æ‰€æœ‰æœåŠ¡å¯åŠ¨å®Œæˆ"
}

# è¿è¡Œå¥åº·æ£€æŸ¥
health_check() {
    log_info "æ‰§è¡Œå¥åº·æ£€æŸ¥..."

    # æ£€æŸ¥ä¸»åº”ç”¨
    if curl -f http://localhost:8080/api/health > /dev/null 2>&1; then
        log_success "âœ“ ä¸»åº”ç”¨å¥åº·æ£€æŸ¥é€šè¿‡"
    else
        log_error "âœ— ä¸»åº”ç”¨å¥åº·æ£€æŸ¥å¤±è´¥"
        return 1
    fi

    # æ£€æŸ¥Nginx
    if curl -f http://localhost > /dev/null 2>&1; then
        log_success "âœ“ Nginxå¥åº·æ£€æŸ¥é€šè¿‡"
    else
        log_warning "âœ— Nginxå¥åº·æ£€æŸ¥å¤±è´¥"
    fi

    # æ£€æŸ¥æ•°æ®åº“è¿æ¥
    if docker exec yyc3-postgres pg_isready -U yyc3 > /dev/null 2>&1; then
        log_success "âœ“ æ•°æ®åº“è¿æ¥æ­£å¸¸"
    else
        log_error "âœ— æ•°æ®åº“è¿æ¥å¤±è´¥"
        return 1
    fi

    # æ£€æŸ¥Redisè¿æ¥
    if docker exec yyc3-redis redis-cli ping > /dev/null 2>&1; then
        log_success "âœ“ Redisè¿æ¥æ­£å¸¸"
    else
        log_error "âœ— Redisè¿æ¥å¤±è´¥"
        return 1
    fi

    log_success "å¥åº·æ£€æŸ¥å®Œæˆ"
}

# æ˜¾ç¤ºæœåŠ¡çŠ¶æ€
show_status() {
    log_info "æœåŠ¡çŠ¶æ€:"
    docker-compose ps

    echo ""
    log_info "æœåŠ¡è®¿é—®åœ°å€:"
    echo "ğŸŒ ä¸»åº”ç”¨: http://localhost:8080"
    echo "ğŸŒ Nginx: http://localhost"
    echo "ğŸ“Š Grafana: http://localhost:3001 (admin: admin)"
    echo "ğŸ“ˆ Prometheus: http://localhost:9090"
    echo "ğŸ” Kibana: http://localhost:5601"

    if docker ps --format "table {{.Names}}" | grep -q "yyc3-adminer"; then
        echo "ğŸ—„ï¸  æ•°æ®åº“ç®¡ç†: http://localhost:8080"
    fi

    if docker ps --format "table {{.Names}}" | grep -q "yyc3-redis-commander"; then
        echo "ğŸ”´ Redisç®¡ç†: http://localhost:8081"
    fi
}

# æ¸…ç†å‡½æ•°
cleanup() {
    log_info "æ¸…ç†æ—§å®¹å™¨å’Œé•œåƒ..."
    docker-compose down
    docker system prune -f
    log_success "æ¸…ç†å®Œæˆ"
}

# ä¸»å‡½æ•°
main() {
    local command=${1:-deploy}
    local env=${2:-production}

    echo "ğŸš€ YYCÂ³ AIå°è¯­æ™ºèƒ½æˆé•¿å®ˆæŠ¤ç³»ç»Ÿ - Dockeréƒ¨ç½²ç®¡ç†"
    echo "=================================================="

    case $command in
        "deploy")
            check_dependencies
            create_directories
            check_env_file
            generate_ssl_cert
            create_database_init
            deploy_services $env
            wait_for_services
            health_check
            show_status
            ;;
        "update")
            log_info "æ›´æ–°æœåŠ¡..."
            deploy_services $env
            wait_for_services
            health_check
            show_status
            ;;
        "stop")
            log_info "åœæ­¢æœåŠ¡..."
            docker-compose down
            log_success "æœåŠ¡å·²åœæ­¢"
            ;;
        "restart")
            log_info "é‡å¯æœåŠ¡..."
            docker-compose restart
            wait_for_services
            health_check
            ;;
        "logs")
            docker-compose logs -f
            ;;
        "status")
            show_status
            ;;
        "cleanup")
            cleanup
            ;;
        "health")
            health_check
            ;;
        *)
            echo "ç”¨æ³•: $0 {deploy|update|stop|restart|logs|status|cleanup|health} [production|development]"
            echo ""
            echo "å‘½ä»¤è¯´æ˜:"
            echo "  deploy     - é¦–æ¬¡éƒ¨ç½²æ‰€æœ‰æœåŠ¡"
            echo "  update     - æ›´æ–°ç°æœ‰æœåŠ¡"
            echo "  stop       - åœæ­¢æ‰€æœ‰æœåŠ¡"
            echo "  restart    - é‡å¯æ‰€æœ‰æœåŠ¡"
            echo "  logs       - æŸ¥çœ‹æœåŠ¡æ—¥å¿—"
            echo "  status     - æ˜¾ç¤ºæœåŠ¡çŠ¶æ€"
            echo "  cleanup    - æ¸…ç†å®¹å™¨å’Œé•œåƒ"
            echo "  health     - æ‰§è¡Œå¥åº·æ£€æŸ¥"
            exit 1
            ;;
    esac
}

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"